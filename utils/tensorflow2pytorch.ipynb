{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dependencies.facenet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b209bfa40634>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfacenet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfacenet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfacenet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minception_resnet_v1\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_mdl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfacenet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdetect_face\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dependencies.facenet'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import json\n",
    "import os, sys\n",
    "\n",
    "from dependencies.facenet.src import facenet\n",
    "from dependencies.facenet.src.models import inception_resnet_v1 as tf_mdl\n",
    "from dependencies.facenet.src.align import detect_face\n",
    "\n",
    "from models.inception_resnet_v1 import InceptionResnetV1\n",
    "from models.mtcnn import PNet, RNet, ONet\n",
    "\n",
    "\n",
    "def import_tf_params(tf_mdl_dir, sess):\n",
    "    \"\"\"Import tensorflow model from save directory.\n",
    "    \n",
    "    Arguments:\n",
    "        tf_mdl_dir {str} -- Location of protobuf, checkpoint, meta files.\n",
    "        sess {tensorflow.Session} -- Tensorflow session object.\n",
    "    \n",
    "    Returns:\n",
    "        (list, list, list) -- Tuple of lists containing the layer names,\n",
    "            parameter arrays as numpy ndarrays, parameter shapes.\n",
    "    \"\"\"\n",
    "    print('\\nLoading tensorflow model\\n')\n",
    "    if callable(tf_mdl_dir):\n",
    "        tf_mdl_dir(sess)\n",
    "    else:\n",
    "        facenet.load_model(tf_mdl_dir)\n",
    "\n",
    "    print('\\nGetting model weights\\n')\n",
    "    tf_layers = tf.trainable_variables()\n",
    "    tf_params = sess.run(tf_layers)\n",
    "\n",
    "    tf_shapes = [p.shape for p in tf_params]\n",
    "    tf_layers = [l.name for l in tf_layers]\n",
    "\n",
    "    if not callable(tf_mdl_dir):\n",
    "        path = os.path.join(tf_mdl_dir, 'layer_description.json')\n",
    "    else:\n",
    "        path = 'data/layer_description.json'\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump({l: s for l, s in zip(tf_layers, tf_shapes)}, f)\n",
    "\n",
    "    return tf_layers, tf_params, tf_shapes\n",
    "\n",
    "\n",
    "def get_layer_indices(layer_lookup, tf_layers):\n",
    "    \"\"\"Giving a lookup of model layer attribute names and tensorflow variable names,\n",
    "    find matching parameters.\n",
    "    \n",
    "    Arguments:\n",
    "        layer_lookup {dict} -- Dictionary mapping pytorch attribute names to (partial)\n",
    "            tensorflow variable names. Expects dict of the form {'attr': ['tf_name', ...]}\n",
    "            where the '...'s are ignored.\n",
    "        tf_layers {list} -- List of tensorflow variable names.\n",
    "    \n",
    "    Returns:\n",
    "        list -- The input dictionary with the list of matching inds appended to each item.\n",
    "    \"\"\"\n",
    "    layer_inds = {}\n",
    "    for name, value in layer_lookup.items():\n",
    "        layer_inds[name] = value + [[i for i, n in enumerate(tf_layers) if value[0] in n]]\n",
    "    return layer_inds\n",
    "\n",
    "\n",
    "def load_tf_batchNorm(weights, layer):\n",
    "    \"\"\"Load tensorflow weights into nn.BatchNorm object.\n",
    "    \n",
    "    Arguments:\n",
    "        weights {list} -- Tensorflow parameters.\n",
    "        layer {torch.nn.Module} -- nn.BatchNorm.\n",
    "    \"\"\"\n",
    "    layer.bias.data = torch.tensor(weights[0]).view(layer.bias.data.shape)\n",
    "    layer.weight.data = torch.ones_like(layer.weight.data)\n",
    "    layer.running_mean = torch.tensor(weights[1]).view(layer.running_mean.shape)\n",
    "    layer.running_var = torch.tensor(weights[2]).view(layer.running_var.shape)\n",
    "\n",
    "\n",
    "def load_tf_conv2d(weights, layer, transpose=False):\n",
    "    \"\"\"Load tensorflow weights into nn.Conv2d object.\n",
    "    \n",
    "    Arguments:\n",
    "        weights {list} -- Tensorflow parameters.\n",
    "        layer {torch.nn.Module} -- nn.Conv2d.\n",
    "    \"\"\"\n",
    "    if isinstance(weights, list):\n",
    "        if len(weights) == 2:\n",
    "            layer.bias.data = (\n",
    "                torch.tensor(weights[1])\n",
    "                    .view(layer.bias.data.shape)\n",
    "            )\n",
    "        weights = weights[0]\n",
    "    \n",
    "    if transpose:\n",
    "        dim_order = (3, 2, 1, 0)\n",
    "    else:\n",
    "        dim_order = (3, 2, 0, 1)\n",
    "\n",
    "    layer.weight.data = (\n",
    "        torch.tensor(weights)\n",
    "            .permute(dim_order)\n",
    "            .view(layer.weight.data.shape)\n",
    "    )\n",
    "\n",
    "\n",
    "def load_tf_conv2d_trans(weights, layer):\n",
    "    return load_tf_conv2d(weights, layer, transpose=True)\n",
    "\n",
    "\n",
    "def load_tf_basicConv2d(weights, layer):\n",
    "    \"\"\"Load tensorflow weights into grouped Conv2d+BatchNorm object.\n",
    "    \n",
    "    Arguments:\n",
    "        weights {list} -- Tensorflow parameters.\n",
    "        layer {torch.nn.Module} -- Object containing Conv2d+BatchNorm.\n",
    "    \"\"\"\n",
    "    load_tf_conv2d(weights[0], layer.conv)\n",
    "    load_tf_batchNorm(weights[1:], layer.bn)\n",
    "\n",
    "\n",
    "def load_tf_linear(weights, layer):\n",
    "    \"\"\"Load tensorflow weights into nn.Linear object.\n",
    "    \n",
    "    Arguments:\n",
    "        weights {list} -- Tensorflow parameters.\n",
    "        layer {torch.nn.Module} -- nn.Linear.\n",
    "    \"\"\"\n",
    "    if isinstance(weights, list):\n",
    "        if len(weights) == 2:\n",
    "            layer.bias.data = (\n",
    "                torch.tensor(weights[1])\n",
    "                    .view(layer.bias.data.shape)\n",
    "            )\n",
    "        weights = weights[0]\n",
    "    layer.weight.data = (\n",
    "        torch.tensor(weights)\n",
    "            .transpose(-1, 0)\n",
    "            .view(layer.weight.data.shape)\n",
    "    )\n",
    "\n",
    "\n",
    "# High-level parameter-loading functions:\n",
    "\n",
    "def load_tf_block35(weights, layer):\n",
    "    load_tf_basicConv2d(weights[:4], layer.branch0)\n",
    "    load_tf_basicConv2d(weights[4:8], layer.branch1[0])\n",
    "    load_tf_basicConv2d(weights[8:12], layer.branch1[1])\n",
    "    load_tf_basicConv2d(weights[12:16], layer.branch2[0])\n",
    "    load_tf_basicConv2d(weights[16:20], layer.branch2[1])\n",
    "    load_tf_basicConv2d(weights[20:24], layer.branch2[2])\n",
    "    load_tf_conv2d(weights[24:26], layer.conv2d)\n",
    "\n",
    "\n",
    "def load_tf_block17_8(weights, layer):\n",
    "    load_tf_basicConv2d(weights[:4], layer.branch0)\n",
    "    load_tf_basicConv2d(weights[4:8], layer.branch1[0])\n",
    "    load_tf_basicConv2d(weights[8:12], layer.branch1[1])\n",
    "    load_tf_basicConv2d(weights[12:16], layer.branch1[2])\n",
    "    load_tf_conv2d(weights[16:18], layer.conv2d)\n",
    "\n",
    "\n",
    "def load_tf_mixed6a(weights, layer):\n",
    "    if len(weights) != 16:\n",
    "        raise ValueError(f'Number of weight arrays ({len(weights)}) not equal to 16')\n",
    "    load_tf_basicConv2d(weights[:4], layer.branch0)\n",
    "    load_tf_basicConv2d(weights[4:8], layer.branch1[0])\n",
    "    load_tf_basicConv2d(weights[8:12], layer.branch1[1])\n",
    "    load_tf_basicConv2d(weights[12:16], layer.branch1[2])\n",
    "\n",
    "\n",
    "def load_tf_mixed7a(weights, layer):\n",
    "    if len(weights) != 28:\n",
    "        raise ValueError(f'Number of weight arrays ({len(weights)}) not equal to 28')\n",
    "    load_tf_basicConv2d(weights[:4], layer.branch0[0])\n",
    "    load_tf_basicConv2d(weights[4:8], layer.branch0[1])\n",
    "    load_tf_basicConv2d(weights[8:12], layer.branch1[0])\n",
    "    load_tf_basicConv2d(weights[12:16], layer.branch1[1])\n",
    "    load_tf_basicConv2d(weights[16:20], layer.branch2[0])\n",
    "    load_tf_basicConv2d(weights[20:24], layer.branch2[1])\n",
    "    load_tf_basicConv2d(weights[24:28], layer.branch2[2])\n",
    "\n",
    "\n",
    "def load_tf_repeats(weights, layer, rptlen, subfun):\n",
    "    if len(weights) % rptlen != 0:\n",
    "        raise ValueError(f'Number of weight arrays ({len(weights)}) not divisible by {rptlen}')\n",
    "    weights_split = [weights[i:i+rptlen] for i in range(0, len(weights), rptlen)]\n",
    "    for i, w in enumerate(weights_split):\n",
    "        subfun(w, getattr(layer, str(i)))\n",
    "\n",
    "\n",
    "def load_tf_repeat_1(weights, layer):\n",
    "    load_tf_repeats(weights, layer, 26, load_tf_block35)\n",
    "\n",
    "\n",
    "def load_tf_repeat_2(weights, layer):\n",
    "    load_tf_repeats(weights, layer, 18, load_tf_block17_8)\n",
    "\n",
    "\n",
    "def load_tf_repeat_3(weights, layer):\n",
    "    load_tf_repeats(weights, layer, 18, load_tf_block17_8)\n",
    "\n",
    "\n",
    "def test_loaded_params(mdl, tf_params, tf_layers):\n",
    "    \"\"\"Check each parameter in a pytorch model for an equivalent parameter\n",
    "    in a list of tensorflow variables.\n",
    "    \n",
    "    Arguments:\n",
    "        mdl {torch.nn.Module} -- Pytorch model.\n",
    "        tf_params {list} -- List of ndarrays representing tensorflow variables.\n",
    "        tf_layers {list} -- Corresponding list of tensorflow variable names.\n",
    "    \"\"\"\n",
    "    tf_means = torch.stack([torch.tensor(p).mean() for p in tf_params])\n",
    "    for name, param in mdl.named_parameters():\n",
    "        pt_mean = param.data.mean()\n",
    "        matching_inds = ((tf_means - pt_mean).abs() < 1e-8).nonzero()\n",
    "        print(f'{name} equivalent to {[tf_layers[i] for i in matching_inds]}')\n",
    "\n",
    "\n",
    "def compare_model_outputs(pt_mdl, sess, test_data):\n",
    "    \"\"\"Given some testing data, compare the output of pytorch and tensorflow models.\n",
    "    \n",
    "    Arguments:\n",
    "        pt_mdl {torch.nn.Module} -- Pytorch model.\n",
    "        sess {tensorflow.Session} -- Tensorflow session object.\n",
    "        test_data {torch.Tensor} -- Pytorch tensor.\n",
    "    \"\"\"\n",
    "    print('\\nPassing test data through TF model\\n')\n",
    "    if isinstance(sess, tf.Session):\n",
    "        images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "        phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "        embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "        feed_dict = {images_placeholder: test_data.numpy(), phase_train_placeholder: False}\n",
    "        tf_output = torch.tensor(sess.run(embeddings, feed_dict=feed_dict))\n",
    "    else:\n",
    "        tf_output = sess(test_data)\n",
    "\n",
    "    print(tf_output)\n",
    "\n",
    "    print('\\nPassing test data through PT model\\n')\n",
    "    pt_output = pt_mdl(test_data.permute(0, 3, 1, 2))\n",
    "    print(pt_output)\n",
    "\n",
    "    distance = (tf_output - pt_output).norm()\n",
    "    print(f'\\nDistance {distance}\\n')\n",
    "\n",
    "\n",
    "def compare_mtcnn(pt_mdl, tf_fun, sess, ind, test_data):\n",
    "    tf_mdls = tf_fun(sess)\n",
    "    tf_mdl = tf_mdls[ind]\n",
    "\n",
    "    print('\\nPassing test data through TF model\\n')\n",
    "    tf_output = tf_mdl(test_data.numpy())\n",
    "    tf_output = [torch.tensor(out) for out in tf_output]\n",
    "    print('\\n'.join([str(o.view(-1)[:10]) for o in tf_output]))\n",
    "\n",
    "    print('\\nPassing test data through PT model\\n')\n",
    "    with torch.no_grad():\n",
    "        pt_output = pt_mdl(test_data.permute(0, 3, 2, 1))\n",
    "    pt_output = [torch.tensor(out) for out in pt_output]\n",
    "    for i in range(len(pt_output)):\n",
    "        if len(pt_output[i].shape) == 4:\n",
    "            pt_output[i] = pt_output[i].permute(0, 3, 2, 1).contiguous()\n",
    "    print('\\n'.join([str(o.view(-1)[:10]) for o in pt_output]))\n",
    "\n",
    "    distance = [(tf_o - pt_o).norm() for tf_o, pt_o in zip(tf_output, pt_output)]\n",
    "    print(f'\\nDistance {distance}\\n')\n",
    "\n",
    "\n",
    "def load_tf_model_weights(mdl, layer_lookup, tf_mdl_dir, is_resnet=True, arg_num=None):\n",
    "    \"\"\"Load tensorflow parameters into a pytorch model.\n",
    "    \n",
    "    Arguments:\n",
    "        mdl {torch.nn.Module} -- Pytorch model.\n",
    "        layer_lookup {[type]} -- Dictionary mapping pytorch attribute names to (partial)\n",
    "            tensorflow variable names, and a function suitable for loading weights.\n",
    "            Expects dict of the form {'attr': ['tf_name', function]}. \n",
    "        tf_mdl_dir {str} -- Location of protobuf, checkpoint, meta files.\n",
    "    \"\"\"\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        tf_layers, tf_params, tf_shapes = import_tf_params(tf_mdl_dir, sess)\n",
    "        layer_info = get_layer_indices(layer_lookup, tf_layers)\n",
    "\n",
    "        for layer_name, info in layer_info.items():\n",
    "            print(f'Loading {info[0]}/* into {layer_name}')\n",
    "            weights = [tf_params[i] for i in info[2]]\n",
    "            layer = getattr(mdl, layer_name)\n",
    "            info[1](weights, layer)\n",
    "\n",
    "        test_loaded_params(mdl, tf_params, tf_layers)\n",
    "\n",
    "        if is_resnet:\n",
    "            compare_model_outputs(mdl, sess, torch.randn(5, 160, 160, 3).detach())\n",
    "\n",
    "\n",
    "def tensorflow2pytorch():\n",
    "    lookup_inception_resnet_v1 = {\n",
    "        'conv2d_1a': ['InceptionResnetV1/Conv2d_1a_3x3', load_tf_basicConv2d],\n",
    "        'conv2d_2a': ['InceptionResnetV1/Conv2d_2a_3x3', load_tf_basicConv2d],\n",
    "        'conv2d_2b': ['InceptionResnetV1/Conv2d_2b_3x3', load_tf_basicConv2d],\n",
    "        'conv2d_3b': ['InceptionResnetV1/Conv2d_3b_1x1', load_tf_basicConv2d],\n",
    "        'conv2d_4a': ['InceptionResnetV1/Conv2d_4a_3x3', load_tf_basicConv2d],\n",
    "        'conv2d_4b': ['InceptionResnetV1/Conv2d_4b_3x3', load_tf_basicConv2d],\n",
    "        'repeat_1': ['InceptionResnetV1/Repeat/block35', load_tf_repeat_1],\n",
    "        'mixed_6a': ['InceptionResnetV1/Mixed_6a', load_tf_mixed6a],\n",
    "        'repeat_2': ['InceptionResnetV1/Repeat_1/block17', load_tf_repeat_2],\n",
    "        'mixed_7a': ['InceptionResnetV1/Mixed_7a', load_tf_mixed7a],\n",
    "        'repeat_3': ['InceptionResnetV1/Repeat_2/block8', load_tf_repeat_3],\n",
    "        'block8': ['InceptionResnetV1/Block8', load_tf_block17_8],\n",
    "        'last_linear': ['InceptionResnetV1/Bottleneck/weights', load_tf_linear],\n",
    "        'last_bn': ['InceptionResnetV1/Bottleneck/BatchNorm', load_tf_batchNorm],\n",
    "        'logits': ['Logits', load_tf_linear],\n",
    "    }\n",
    "\n",
    "    print('\\nLoad VGGFace2-trained weights and save\\n')\n",
    "    mdl = InceptionResnetV1(num_classes=8631).eval()\n",
    "    tf_mdl_dir = 'data/20180402-114759'\n",
    "    data_name = 'vggface2'\n",
    "    load_tf_model_weights(mdl, lookup_inception_resnet_v1, tf_mdl_dir)\n",
    "    state_dict = mdl.state_dict()\n",
    "    torch.save(state_dict, f'{tf_mdl_dir}-{data_name}.pt')    \n",
    "    torch.save(\n",
    "        {\n",
    "            'logits.weight': state_dict['logits.weight'],\n",
    "            'logits.bias': state_dict['logits.bias'],\n",
    "        },\n",
    "        f'{tf_mdl_dir}-{data_name}-logits.pt'\n",
    "    )\n",
    "    state_dict.pop('logits.weight')\n",
    "    state_dict.pop('logits.bias')\n",
    "    torch.save(state_dict, f'{tf_mdl_dir}-{data_name}-features.pt')\n",
    "    \n",
    "    print('\\nLoad CASIA-Webface-trained weights and save\\n')\n",
    "    mdl = InceptionResnetV1(num_classes=10575).eval()\n",
    "    tf_mdl_dir = 'data/20180408-102900'\n",
    "    data_name = 'casia-webface'\n",
    "    load_tf_model_weights(mdl, lookup_inception_resnet_v1, tf_mdl_dir)\n",
    "    state_dict = mdl.state_dict()\n",
    "    torch.save(state_dict, f'{tf_mdl_dir}-{data_name}.pt')    \n",
    "    torch.save(\n",
    "        {\n",
    "            'logits.weight': state_dict['logits.weight'],\n",
    "            'logits.bias': state_dict['logits.bias'],\n",
    "        },\n",
    "        f'{tf_mdl_dir}-{data_name}-logits.pt'\n",
    "    )\n",
    "    state_dict.pop('logits.weight')\n",
    "    state_dict.pop('logits.bias')\n",
    "    torch.save(state_dict, f'{tf_mdl_dir}-{data_name}-features.pt')\n",
    "    \n",
    "    lookup_pnet = {\n",
    "        'conv1': ['pnet/conv1', load_tf_conv2d_trans],\n",
    "        'prelu1': ['pnet/PReLU1', load_tf_linear],\n",
    "        'conv2': ['pnet/conv2', load_tf_conv2d_trans],\n",
    "        'prelu2': ['pnet/PReLU2', load_tf_linear],\n",
    "        'conv3': ['pnet/conv3', load_tf_conv2d_trans],\n",
    "        'prelu3': ['pnet/PReLU3', load_tf_linear],\n",
    "        'conv4_1': ['pnet/conv4-1', load_tf_conv2d_trans],\n",
    "        'conv4_2': ['pnet/conv4-2', load_tf_conv2d_trans],\n",
    "    }\n",
    "    lookup_rnet = {\n",
    "        'conv1': ['rnet/conv1', load_tf_conv2d_trans],\n",
    "        'prelu1': ['rnet/prelu1', load_tf_linear],\n",
    "        'conv2': ['rnet/conv2', load_tf_conv2d_trans],\n",
    "        'prelu2': ['rnet/prelu2', load_tf_linear],\n",
    "        'conv3': ['rnet/conv3', load_tf_conv2d_trans],\n",
    "        'prelu3': ['rnet/prelu3', load_tf_linear],\n",
    "        'dense4': ['rnet/conv4', load_tf_linear],\n",
    "        'prelu4': ['rnet/prelu4', load_tf_linear],\n",
    "        'dense5_1': ['rnet/conv5-1', load_tf_linear],\n",
    "        'dense5_2': ['rnet/conv5-2', load_tf_linear],\n",
    "    }\n",
    "    lookup_onet = {\n",
    "        'conv1': ['onet/conv1', load_tf_conv2d_trans],\n",
    "        'prelu1': ['onet/prelu1', load_tf_linear],\n",
    "        'conv2': ['onet/conv2', load_tf_conv2d_trans],\n",
    "        'prelu2': ['onet/prelu2', load_tf_linear],\n",
    "        'conv3': ['onet/conv3', load_tf_conv2d_trans],\n",
    "        'prelu3': ['onet/prelu3', load_tf_linear],\n",
    "        'conv4': ['onet/conv4', load_tf_conv2d_trans],\n",
    "        'prelu4': ['onet/prelu4', load_tf_linear],\n",
    "        'dense5': ['onet/conv5', load_tf_linear],\n",
    "        'prelu5': ['onet/prelu5', load_tf_linear],\n",
    "        'dense6_1': ['onet/conv6-1', load_tf_linear],\n",
    "        'dense6_2': ['onet/conv6-2', load_tf_linear],\n",
    "        'dense6_3': ['onet/conv6-3', load_tf_linear],\n",
    "    }\n",
    "\n",
    "    print('\\nLoad PNet weights and save\\n')\n",
    "    tf_mdl_dir = lambda sess: detect_face.create_mtcnn(sess, None)\n",
    "    mdl = PNet()\n",
    "    data_name = 'pnet'\n",
    "    load_tf_model_weights(mdl, lookup_pnet, tf_mdl_dir, is_resnet=False, arg_num=0)\n",
    "    torch.save(mdl.state_dict(), f'data/{data_name}.pt')\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        compare_mtcnn(mdl, tf_mdl_dir, sess, 0, torch.randn(1, 256, 256, 3).detach())\n",
    "\n",
    "    print('\\nLoad RNet weights and save\\n')\n",
    "    mdl = RNet()\n",
    "    data_name = 'rnet'\n",
    "    load_tf_model_weights(mdl, lookup_rnet, tf_mdl_dir, is_resnet=False, arg_num=1)\n",
    "    torch.save(mdl.state_dict(), f'data/{data_name}.pt')\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        compare_mtcnn(mdl, tf_mdl_dir, sess, 1, torch.randn(1, 24, 24, 3).detach())\n",
    "\n",
    "    print('\\nLoad ONet weights and save\\n')\n",
    "    mdl = ONet()\n",
    "    data_name = 'onet'\n",
    "    load_tf_model_weights(mdl, lookup_onet, tf_mdl_dir, is_resnet=False, arg_num=2)\n",
    "    torch.save(mdl.state_dict(), f'data/{data_name}.pt')\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        compare_mtcnn(mdl, tf_mdl_dir, sess, 2, torch.randn(1, 48, 48, 3).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
