{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://github.com/ipazc/mtcnn/blob/master/mtcnn/mtcnn.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mtcnn code\n",
    "'''\n",
    "\n",
    "#!/usr/bin/python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2019 Iván de Paz Centeno\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "#\n",
    "# This code is derived from the MTCNN implementation of David Sandberg for Facenet\n",
    "# (https://github.com/davidsandberg/facenet/)\n",
    "# It has been rebuilt from scratch, taking the David Sandberg's implementation as a reference.\n",
    "#\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pkg_resources\n",
    "\n",
    "from mtcnn.exceptions import InvalidImage\n",
    "from mtcnn.network.factory import NetworkFactory\n",
    "\n",
    "__author__ = \"Iván de Paz Centeno\"\n",
    "\n",
    "\n",
    "class StageStatus(object):\n",
    "    \"\"\"\n",
    "    Keeps status between MTCNN stages\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pad_result: tuple = None, width=0, height=0):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.dy = self.edy = self.dx = self.edx = self.y = self.ey = self.x = self.ex = self.tmpw = self.tmph = []\n",
    "\n",
    "        if pad_result is not None:\n",
    "            self.update(pad_result)\n",
    "\n",
    "    def update(self, pad_result: tuple):\n",
    "        s = self\n",
    "        s.dy, s.edy, s.dx, s.edx, s.y, s.ey, s.x, s.ex, s.tmpw, s.tmph = pad_result\n",
    "\n",
    "\n",
    "class MTCNN(object):\n",
    "    \"\"\"\n",
    "    Allows to perform MTCNN Detection ->\n",
    "        a) Detection of faces (with the confidence probability)\n",
    "        b) Detection of keypoints (left eye, right eye, nose, mouth_left, mouth_right)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, weights_file: str = None, min_face_size: int = 20, steps_threshold: list = None,\n",
    "                 scale_factor: float = 0.709):\n",
    "        \"\"\"\n",
    "        Initializes the MTCNN.\n",
    "        :param weights_file: file uri with the weights of the P, R and O networks from MTCNN. By default it will load\n",
    "        the ones bundled with the package.\n",
    "        :param min_face_size: minimum size of the face to detect\n",
    "        :param steps_threshold: step's thresholds values\n",
    "        :param scale_factor: scale factor\n",
    "        \"\"\"\n",
    "        if steps_threshold is None:\n",
    "            steps_threshold = [0.6, 0.7, 0.7]\n",
    "\n",
    "        if weights_file is None:\n",
    "            weights_file = pkg_resources.resource_stream('mtcnn', 'data/mtcnn_weights.npy')\n",
    "\n",
    "        self._min_face_size = min_face_size\n",
    "        self._steps_threshold = steps_threshold\n",
    "        self._scale_factor = scale_factor\n",
    "\n",
    "        self._pnet, self._rnet, self._onet = NetworkFactory().build_P_R_O_nets_from_file(weights_file)\n",
    "\n",
    "    @property\n",
    "    def min_face_size(self):\n",
    "        return self._min_face_size\n",
    "\n",
    "    @min_face_size.setter\n",
    "    def min_face_size(self, mfc=20):\n",
    "        try:\n",
    "            self._min_face_size = int(mfc)\n",
    "        except ValueError:\n",
    "            self._min_face_size = 20\n",
    "\n",
    "    def __compute_scale_pyramid(self, m, min_layer):\n",
    "        scales = []\n",
    "        factor_count = 0\n",
    "\n",
    "        while min_layer >= 12:\n",
    "            scales += [m * np.power(self._scale_factor, factor_count)]\n",
    "            min_layer = min_layer * self._scale_factor\n",
    "            factor_count += 1\n",
    "\n",
    "        return scales\n",
    "\n",
    "    @staticmethod\n",
    "    def __scale_image(image, scale: float):\n",
    "        \"\"\"\n",
    "        Scales the image to a given scale.\n",
    "        :param image:\n",
    "        :param scale:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        height, width, _ = image.shape\n",
    "\n",
    "        width_scaled = int(np.ceil(width * scale))\n",
    "        height_scaled = int(np.ceil(height * scale))\n",
    "\n",
    "        im_data = cv2.resize(image, (width_scaled, height_scaled), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Normalize the image's pixels\n",
    "        im_data_normalized = (im_data - 127.5) * 0.0078125\n",
    "\n",
    "        return im_data_normalized\n",
    "\n",
    "    @staticmethod\n",
    "    def __generate_bounding_box(imap, reg, scale, t):\n",
    "\n",
    "        # use heatmap to generate bounding boxes\n",
    "        stride = 2\n",
    "        cellsize = 12\n",
    "\n",
    "        imap = np.transpose(imap)\n",
    "        dx1 = np.transpose(reg[:, :, 0])\n",
    "        dy1 = np.transpose(reg[:, :, 1])\n",
    "        dx2 = np.transpose(reg[:, :, 2])\n",
    "        dy2 = np.transpose(reg[:, :, 3])\n",
    "\n",
    "        y, x = np.where(imap >= t)\n",
    "\n",
    "        if y.shape[0] == 1:\n",
    "            dx1 = np.flipud(dx1)\n",
    "            dy1 = np.flipud(dy1)\n",
    "            dx2 = np.flipud(dx2)\n",
    "            dy2 = np.flipud(dy2)\n",
    "\n",
    "        score = imap[(y, x)]\n",
    "        reg = np.transpose(np.vstack([dx1[(y, x)], dy1[(y, x)], dx2[(y, x)], dy2[(y, x)]]))\n",
    "\n",
    "        if reg.size == 0:\n",
    "            reg = np.empty(shape=(0, 3))\n",
    "\n",
    "        bb = np.transpose(np.vstack([y, x]))\n",
    "\n",
    "        q1 = np.fix((stride * bb + 1) / scale)\n",
    "        q2 = np.fix((stride * bb + cellsize) / scale)\n",
    "        boundingbox = np.hstack([q1, q2, np.expand_dims(score, 1), reg])\n",
    "\n",
    "        return boundingbox, reg\n",
    "\n",
    "    @staticmethod\n",
    "    def __nms(boxes, threshold, method):\n",
    "        \"\"\"\n",
    "        Non Maximum Suppression.\n",
    "        :param boxes: np array with bounding boxes.\n",
    "        :param threshold:\n",
    "        :param method: NMS method to apply. Available values ('Min', 'Union')\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if boxes.size == 0:\n",
    "            return np.empty((0, 3))\n",
    "\n",
    "        x1 = boxes[:, 0]\n",
    "        y1 = boxes[:, 1]\n",
    "        x2 = boxes[:, 2]\n",
    "        y2 = boxes[:, 3]\n",
    "        s = boxes[:, 4]\n",
    "\n",
    "        area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        sorted_s = np.argsort(s)\n",
    "\n",
    "        pick = np.zeros_like(s, dtype=np.int16)\n",
    "        counter = 0\n",
    "        while sorted_s.size > 0:\n",
    "            i = sorted_s[-1]\n",
    "            pick[counter] = i\n",
    "            counter += 1\n",
    "            idx = sorted_s[0:-1]\n",
    "\n",
    "            xx1 = np.maximum(x1[i], x1[idx])\n",
    "            yy1 = np.maximum(y1[i], y1[idx])\n",
    "            xx2 = np.minimum(x2[i], x2[idx])\n",
    "            yy2 = np.minimum(y2[i], y2[idx])\n",
    "\n",
    "            w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "            h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "\n",
    "            inter = w * h\n",
    "\n",
    "            if method is 'Min':\n",
    "                o = inter / np.minimum(area[i], area[idx])\n",
    "            else:\n",
    "                o = inter / (area[i] + area[idx] - inter)\n",
    "\n",
    "            sorted_s = sorted_s[np.where(o <= threshold)]\n",
    "\n",
    "        pick = pick[0:counter]\n",
    "\n",
    "        return pick\n",
    "\n",
    "    @staticmethod\n",
    "    def __pad(total_boxes, w, h):\n",
    "        # compute the padding coordinates (pad the bounding boxes to square)\n",
    "        tmpw = (total_boxes[:, 2] - total_boxes[:, 0] + 1).astype(np.int32)\n",
    "        tmph = (total_boxes[:, 3] - total_boxes[:, 1] + 1).astype(np.int32)\n",
    "        numbox = total_boxes.shape[0]\n",
    "\n",
    "        dx = np.ones(numbox, dtype=np.int32)\n",
    "        dy = np.ones(numbox, dtype=np.int32)\n",
    "        edx = tmpw.copy().astype(np.int32)\n",
    "        edy = tmph.copy().astype(np.int32)\n",
    "\n",
    "        x = total_boxes[:, 0].copy().astype(np.int32)\n",
    "        y = total_boxes[:, 1].copy().astype(np.int32)\n",
    "        ex = total_boxes[:, 2].copy().astype(np.int32)\n",
    "        ey = total_boxes[:, 3].copy().astype(np.int32)\n",
    "\n",
    "        tmp = np.where(ex > w)\n",
    "        edx.flat[tmp] = np.expand_dims(-ex[tmp] + w + tmpw[tmp], 1)\n",
    "        ex[tmp] = w\n",
    "\n",
    "        tmp = np.where(ey > h)\n",
    "        edy.flat[tmp] = np.expand_dims(-ey[tmp] + h + tmph[tmp], 1)\n",
    "        ey[tmp] = h\n",
    "\n",
    "        tmp = np.where(x < 1)\n",
    "        dx.flat[tmp] = np.expand_dims(2 - x[tmp], 1)\n",
    "        x[tmp] = 1\n",
    "\n",
    "        tmp = np.where(y < 1)\n",
    "        dy.flat[tmp] = np.expand_dims(2 - y[tmp], 1)\n",
    "        y[tmp] = 1\n",
    "\n",
    "        return dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph\n",
    "\n",
    "    @staticmethod\n",
    "    def __rerec(bbox):\n",
    "        # convert bbox to square\n",
    "        height = bbox[:, 3] - bbox[:, 1]\n",
    "        width = bbox[:, 2] - bbox[:, 0]\n",
    "        max_side_length = np.maximum(width, height)\n",
    "        bbox[:, 0] = bbox[:, 0] + width * 0.5 - max_side_length * 0.5\n",
    "        bbox[:, 1] = bbox[:, 1] + height * 0.5 - max_side_length * 0.5\n",
    "        bbox[:, 2:4] = bbox[:, 0:2] + np.transpose(np.tile(max_side_length, (2, 1)))\n",
    "        return bbox\n",
    "\n",
    "    @staticmethod\n",
    "    def __bbreg(boundingbox, reg):\n",
    "        # calibrate bounding boxes\n",
    "        if reg.shape[1] == 1:\n",
    "            reg = np.reshape(reg, (reg.shape[2], reg.shape[3]))\n",
    "\n",
    "        w = boundingbox[:, 2] - boundingbox[:, 0] + 1\n",
    "        h = boundingbox[:, 3] - boundingbox[:, 1] + 1\n",
    "        b1 = boundingbox[:, 0] + reg[:, 0] * w\n",
    "        b2 = boundingbox[:, 1] + reg[:, 1] * h\n",
    "        b3 = boundingbox[:, 2] + reg[:, 2] * w\n",
    "        b4 = boundingbox[:, 3] + reg[:, 3] * h\n",
    "        boundingbox[:, 0:4] = np.transpose(np.vstack([b1, b2, b3, b4]))\n",
    "        return boundingbox\n",
    "\n",
    "    def detect_faces(self, img) -> list:\n",
    "        \"\"\"\n",
    "        Detects bounding boxes from the specified image.\n",
    "        :param img: image to process\n",
    "        :return: list containing all the bounding boxes detected with their keypoints.\n",
    "        \"\"\"\n",
    "        if img is None or not hasattr(img, \"shape\"):\n",
    "            raise InvalidImage(\"Image not valid.\")\n",
    "\n",
    "        height, width, _ = img.shape\n",
    "        stage_status = StageStatus(width=width, height=height)\n",
    "\n",
    "        m = 12 / self._min_face_size\n",
    "        min_layer = np.amin([height, width]) * m\n",
    "\n",
    "        scales = self.__compute_scale_pyramid(m, min_layer)\n",
    "\n",
    "        stages = [self.__stage1, self.__stage2, self.__stage3]\n",
    "        result = [scales, stage_status]\n",
    "\n",
    "        # We pipe here each of the stages\n",
    "        for stage in stages:\n",
    "            result = stage(img, result[0], result[1])\n",
    "\n",
    "        [total_boxes, points] = result\n",
    "\n",
    "        bounding_boxes = []\n",
    "\n",
    "        for bounding_box, keypoints in zip(total_boxes, points.T):\n",
    "            x = max(0, int(bounding_box[0]))\n",
    "            y = max(0, int(bounding_box[1]))\n",
    "            width = int(bounding_box[2] - x)\n",
    "            height = int(bounding_box[3] - y)\n",
    "            bounding_boxes.append({\n",
    "                'box': [x, y, width, height],\n",
    "                'confidence': bounding_box[-1],\n",
    "                'keypoints': {\n",
    "                    'left_eye': (int(keypoints[0]), int(keypoints[5])),\n",
    "                    'right_eye': (int(keypoints[1]), int(keypoints[6])),\n",
    "                    'nose': (int(keypoints[2]), int(keypoints[7])),\n",
    "                    'mouth_left': (int(keypoints[3]), int(keypoints[8])),\n",
    "                    'mouth_right': (int(keypoints[4]), int(keypoints[9])),\n",
    "                }\n",
    "            })\n",
    "\n",
    "        return bounding_boxes\n",
    "\n",
    "    def __stage1(self, image, scales: list, stage_status: StageStatus):\n",
    "        \"\"\"\n",
    "        First stage of the MTCNN.\n",
    "        :param image:\n",
    "        :param scales:\n",
    "        :param stage_status:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        total_boxes = np.empty((0, 9))\n",
    "        status = stage_status\n",
    "\n",
    "        for scale in scales:\n",
    "            scaled_image = self.__scale_image(image, scale)\n",
    "\n",
    "            img_x = np.expand_dims(scaled_image, 0)\n",
    "            img_y = np.transpose(img_x, (0, 2, 1, 3))\n",
    "\n",
    "            out = self._pnet.predict(img_y)\n",
    "\n",
    "            out0 = np.transpose(out[0], (0, 2, 1, 3))\n",
    "            out1 = np.transpose(out[1], (0, 2, 1, 3))\n",
    "\n",
    "            boxes, _ = self.__generate_bounding_box(out1[0, :, :, 1].copy(),\n",
    "                                                    out0[0, :, :, :].copy(), scale, self._steps_threshold[0])\n",
    "\n",
    "            # inter-scale nms\n",
    "            pick = self.__nms(boxes.copy(), 0.5, 'Union')\n",
    "            if boxes.size > 0 and pick.size > 0:\n",
    "                boxes = boxes[pick, :]\n",
    "                total_boxes = np.append(total_boxes, boxes, axis=0)\n",
    "\n",
    "        numboxes = total_boxes.shape[0]\n",
    "\n",
    "        if numboxes > 0:\n",
    "            pick = self.__nms(total_boxes.copy(), 0.7, 'Union')\n",
    "            total_boxes = total_boxes[pick, :]\n",
    "\n",
    "            regw = total_boxes[:, 2] - total_boxes[:, 0]\n",
    "            regh = total_boxes[:, 3] - total_boxes[:, 1]\n",
    "\n",
    "            qq1 = total_boxes[:, 0] + total_boxes[:, 5] * regw\n",
    "            qq2 = total_boxes[:, 1] + total_boxes[:, 6] * regh\n",
    "            qq3 = total_boxes[:, 2] + total_boxes[:, 7] * regw\n",
    "            qq4 = total_boxes[:, 3] + total_boxes[:, 8] * regh\n",
    "\n",
    "            total_boxes = np.transpose(np.vstack([qq1, qq2, qq3, qq4, total_boxes[:, 4]]))\n",
    "            total_boxes = self.__rerec(total_boxes.copy())\n",
    "\n",
    "            total_boxes[:, 0:4] = np.fix(total_boxes[:, 0:4]).astype(np.int32)\n",
    "            status = StageStatus(self.__pad(total_boxes.copy(), stage_status.width, stage_status.height),\n",
    "                                 width=stage_status.width, height=stage_status.height)\n",
    "\n",
    "        return total_boxes, status\n",
    "\n",
    "    def __stage2(self, img, total_boxes, stage_status: StageStatus):\n",
    "        \"\"\"\n",
    "        Second stage of the MTCNN.\n",
    "        :param img:\n",
    "        :param total_boxes:\n",
    "        :param stage_status:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        num_boxes = total_boxes.shape[0]\n",
    "        if num_boxes == 0:\n",
    "            return total_boxes, stage_status\n",
    "\n",
    "        # second stage\n",
    "        tempimg = np.zeros(shape=(24, 24, 3, num_boxes))\n",
    "\n",
    "        for k in range(0, num_boxes):\n",
    "            tmp = np.zeros((int(stage_status.tmph[k]), int(stage_status.tmpw[k]), 3))\n",
    "\n",
    "            tmp[stage_status.dy[k] - 1:stage_status.edy[k], stage_status.dx[k] - 1:stage_status.edx[k], :] = \\\n",
    "                img[stage_status.y[k] - 1:stage_status.ey[k], stage_status.x[k] - 1:stage_status.ex[k], :]\n",
    "\n",
    "            if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n",
    "                tempimg[:, :, :, k] = cv2.resize(tmp, (24, 24), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            else:\n",
    "                return np.empty(shape=(0,)), stage_status\n",
    "\n",
    "        tempimg = (tempimg - 127.5) * 0.0078125\n",
    "        tempimg1 = np.transpose(tempimg, (3, 1, 0, 2))\n",
    "\n",
    "        out = self._rnet.predict(tempimg1)\n",
    "\n",
    "        out0 = np.transpose(out[0])\n",
    "        out1 = np.transpose(out[1])\n",
    "\n",
    "        score = out1[1, :]\n",
    "\n",
    "        ipass = np.where(score > self._steps_threshold[1])\n",
    "\n",
    "        total_boxes = np.hstack([total_boxes[ipass[0], 0:4].copy(), np.expand_dims(score[ipass].copy(), 1)])\n",
    "\n",
    "        mv = out0[:, ipass[0]]\n",
    "\n",
    "        if total_boxes.shape[0] > 0:\n",
    "            pick = self.__nms(total_boxes, 0.7, 'Union')\n",
    "            total_boxes = total_boxes[pick, :]\n",
    "            total_boxes = self.__bbreg(total_boxes.copy(), np.transpose(mv[:, pick]))\n",
    "            total_boxes = self.__rerec(total_boxes.copy())\n",
    "\n",
    "        return total_boxes, stage_status\n",
    "\n",
    "    def __stage3(self, img, total_boxes, stage_status: StageStatus):\n",
    "        \"\"\"\n",
    "        Third stage of the MTCNN.\n",
    "        :param img:\n",
    "        :param total_boxes:\n",
    "        :param stage_status:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num_boxes = total_boxes.shape[0]\n",
    "        if num_boxes == 0:\n",
    "            return total_boxes, np.empty(shape=(0,))\n",
    "\n",
    "        total_boxes = np.fix(total_boxes).astype(np.int32)\n",
    "\n",
    "        status = StageStatus(self.__pad(total_boxes.copy(), stage_status.width, stage_status.height),\n",
    "                             width=stage_status.width, height=stage_status.height)\n",
    "\n",
    "        tempimg = np.zeros((48, 48, 3, num_boxes))\n",
    "\n",
    "        for k in range(0, num_boxes):\n",
    "\n",
    "            tmp = np.zeros((int(status.tmph[k]), int(status.tmpw[k]), 3))\n",
    "\n",
    "            tmp[status.dy[k] - 1:status.edy[k], status.dx[k] - 1:status.edx[k], :] = \\\n",
    "                img[status.y[k] - 1:status.ey[k], status.x[k] - 1:status.ex[k], :]\n",
    "\n",
    "            if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n",
    "                tempimg[:, :, :, k] = cv2.resize(tmp, (48, 48), interpolation=cv2.INTER_AREA)\n",
    "            else:\n",
    "                return np.empty(shape=(0,)), np.empty(shape=(0,))\n",
    "\n",
    "        tempimg = (tempimg - 127.5) * 0.0078125\n",
    "        tempimg1 = np.transpose(tempimg, (3, 1, 0, 2))\n",
    "\n",
    "        out = self._onet.predict(tempimg1)\n",
    "        out0 = np.transpose(out[0])\n",
    "        out1 = np.transpose(out[1])\n",
    "        out2 = np.transpose(out[2])\n",
    "\n",
    "        score = out2[1, :]\n",
    "\n",
    "        points = out1\n",
    "\n",
    "        ipass = np.where(score > self._steps_threshold[2])\n",
    "\n",
    "        points = points[:, ipass[0]]\n",
    "\n",
    "        total_boxes = np.hstack([total_boxes[ipass[0], 0:4].copy(), np.expand_dims(score[ipass].copy(), 1)])\n",
    "\n",
    "        mv = out0[:, ipass[0]]\n",
    "\n",
    "        w = total_boxes[:, 2] - total_boxes[:, 0] + 1\n",
    "        h = total_boxes[:, 3] - total_boxes[:, 1] + 1\n",
    "\n",
    "        points[0:5, :] = np.tile(w, (5, 1)) * points[0:5, :] + np.tile(total_boxes[:, 0], (5, 1)) - 1\n",
    "        points[5:10, :] = np.tile(h, (5, 1)) * points[5:10, :] + np.tile(total_boxes[:, 1], (5, 1)) - 1\n",
    "\n",
    "        if total_boxes.shape[0] > 0:\n",
    "            total_boxes = self.__bbreg(total_boxes.copy(), np.transpose(mv))\n",
    "            pick = self.__nms(total_boxes.copy(), 0.7, 'Min')\n",
    "            total_boxes = total_boxes[pick, :]\n",
    "            points = points[:, pick]\n",
    "\n",
    "        return total_boxes, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-model",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-spain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026BD1E94700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000026BD1E94700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "\n",
    "video = cv2.VideoCapture('./debate.mp4')\n",
    "\n",
    "if video.isOpened() == False:\n",
    "    print('Cannot open this File')\n",
    "    exit()\n",
    "    \n",
    "title = ['window']\n",
    "\n",
    "for i in title:\n",
    "    cv2.namedWindow(i)\n",
    "    \n",
    "width = video.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = video.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "co = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "filename = 'debate_mtcnn.avi'\n",
    "\n",
    "make = cv2.VideoWriter(filename, co, fps, (int(width), int(height)))\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    detector = MTCNN()\n",
    "    \n",
    "    detector.detect_faces(gray_frame)\n",
    "    \n",
    "    if cv2.waitKey() & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    cv2.imshow(title[0], frame)\n",
    "    \n",
    "    make.write(frame)\n",
    "\n",
    "video.release()\n",
    "make.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-blind",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-chinese",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-airport",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-injury",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-island",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-minutes",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
