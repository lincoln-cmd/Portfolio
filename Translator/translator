'''
from: https://www.thepythoncode.com/article/machine-translation-using-huggingface-transformers-in-python
'''
from transformers import *

########################################
# translate English to German
'''
src = 'en'
dst = 'de'

task_name = f'translation_{src}_to_{dst}'
model_name = f'Helsinki-NLP/opus-mt-{src}-{dst}'

translator = pipeline(task_name, model = model_name, tokenizer = model_name)

#print(translator('You\'re a genius.')[0]['translation_text'])

'''

article = """
Albert Einstein ( 14 March 1879 – 18 April 1955) was a German-born theoretical physicist, widely acknowledged to be one of the greatest physicists of all time. 
Einstein is best known for developing the theory of relativity, but he also made important contributions to the development of the theory of quantum mechanics. 
Relativity and quantum mechanics are together the two pillars of modern physics. 
His mass–energy equivalence formula E = mc2, which arises from relativity theory, has been dubbed "the world's most famous equation". 
His work is also known for its influence on the philosophy of science.
He received the 1921 Nobel Prize in Physics "for his services to theoretical physics, and especially for his discovery of the law of the photoelectric effect", a pivotal step in the development of quantum theory. 
His intellectual achievements and originality resulted in "Einstein" becoming synonymous with "genius"
"""

#print(translator(article)[0]["translation_text"])

'''
def get_translation_model_and_tokenizer(src_lang, dst_lang):
    """
  Given the source and destination languages, returns the appropriate model
  See the language codes here: https://developers.google.com/admin-sdk/directory/v1/languages
  For the 3-character language codes, you can google for the code!
  """
    model_name = f'Helsinki-NLP/opus-mt-{src}-{dst}'
    
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
    
    return model, tokenizer
'''

#############################################
# translate English to Chinese

article2 = 'Hello. Nice to meet you.'

src = 'en'
dst = 'zh'

'''
model, tokenizer = get_translation_model_and_tokenizer(src, dst)
inputs = tokenizer.encode(article, return_tensors = 'pt', max_lenth = 512, truncation = True)
#print(inputs)


greedy_outputs = model.generate(inputs)
print(tokenizer.decode(greedy_outputs[0], skip_special_tokens = True))

beam_outputs = model.generate(inputs, num_beams = 3)
print(tokenizer.decode(beam_outputs[0], skip_special_tokens = True))
'''



####################################
# test in Chinese, German, and Arabic


src1 = 'en'
dst1 = 'zh'

task_name1 = f'translation_{src1}_to_{dst1}'
model_name1 = f'Helsinki-NLP/opus-mt-{src1}-{dst1}'

translator1 = pipeline(task_name1, model = model_name1, tokenizer = model_name1)



src2 = 'en'
dst2 = 'ar'

task_name2 = f'translation_{src2}_to_{dst2}'
model_name2 = f'Helsinki-NLP/opus-mt-{src2}-{dst2}'

translator2 = pipeline(task_name2, model = model_name2, tokenizer = model_name2)



src3 = 'en'
dst3 = 'de'

task_name3 = f'translation_{src3}_to_{dst3}'
model_name3 = f'Helsinki-NLP/opus-mt-{src3}-{dst3}'

translator3 = pipeline(task_name2, model = model_name2, tokenizer = model_name3)

print("Hello. Nice to meet you.")
print('in chinese : ', translator(article2)[0]["translation_text"])
print('in arabic : ', translator2(article2)[0]["translation_text"])
print('in german : ', translator3(article2)[0]["translation_text"])

#################################################
# translate English to Arabic
'''
src = 'en'
dst = 'ar'

task_name = f'translation_{src}_to_{dst}'
model_name = f'Helsinki-NLP/opus-mt-{src}-{dst}'

translator = pipeline(task_name, model = model_name, tokenizer = model_name)

print(translator(article)[0]["translation_text"])
'''

'''
model, tokenizer = get_translation_model_and_tokenizer(src, dst)

text = 'It can be sever, and has caused millions of deaths around the world as well as lasting health problems in some who have survived the illness.'
inputs = tokenizer.encode(text, return_tensors='pt', max_length = 512, truncation = True)

beam_outputs = model.generate(inputs, num_beams = 5, num_return_sequences = 5, early_stopping = True)
for i, beam_output in enumerate(beam_outputs):
    print(tokenizer.decode(beam_output, skip_special_tokens = True))
    print('='*50)
'''
